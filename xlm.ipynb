{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "09f58533",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 1;\n",
       "                var nbb_unformatted_code = \"%load_ext nb_black\";\n",
       "                var nbb_formatted_code = \"%load_ext nb_black\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext nb_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ce3233e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2;\n",
       "                var nbb_unformatted_code = \"import torch\\ntorch.manual_seed(0)\\ntorch.use_deterministic_algorithms(False)\\n\\nimport random\\nrandom.seed(0)\\n\\nimport numpy as np\\nnp.random.seed(0)\";\n",
       "                var nbb_formatted_code = \"import torch\\n\\ntorch.manual_seed(0)\\ntorch.use_deterministic_algorithms(False)\\n\\nimport random\\n\\nrandom.seed(0)\\n\\nimport numpy as np\\n\\nnp.random.seed(0)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "torch.manual_seed(0)\n",
    "torch.use_deterministic_algorithms(False)\n",
    "\n",
    "import random\n",
    "random.seed(0)\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6eb0c6c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 3;\n",
       "                var nbb_unformatted_code = \"if torch.cuda.is_available():\\n    dev = \\\"cuda:1\\\"\\nelse:\\n    dev = \\\"cpu\\\"\\nDEVICE = torch.device(dev)\";\n",
       "                var nbb_formatted_code = \"if torch.cuda.is_available():\\n    dev = \\\"cuda:1\\\"\\nelse:\\n    dev = \\\"cpu\\\"\\nDEVICE = torch.device(dev)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    dev = \"cuda:1\"\n",
    "else:\n",
    "    dev = \"cpu\"\n",
    "DEVICE = torch.device(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "579ddd2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 4;\n",
       "                var nbb_unformatted_code = \"import torch\\nfrom transformers import XLMTokenizer, XLMWithLMHeadModel\\n\\n# tokenizer = XLMTokenizer.from_pretrained(\\\"xlm-mlm-100-1280\\\")\\n# model = XLMWithLMHeadModel.from_pretrained(\\\"xlm-mlm-100-1280\\\")\";\n",
       "                var nbb_formatted_code = \"import torch\\nfrom transformers import XLMTokenizer, XLMWithLMHeadModel\\n\\n# tokenizer = XLMTokenizer.from_pretrained(\\\"xlm-mlm-100-1280\\\")\\n# model = XLMWithLMHeadModel.from_pretrained(\\\"xlm-mlm-100-1280\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import XLMTokenizer, XLMWithLMHeadModel\n",
    "\n",
    "# tokenizer = XLMTokenizer.from_pretrained(\"xlm-mlm-100-1280\")\n",
    "# model = XLMWithLMHeadModel.from_pretrained(\"xlm-mlm-100-1280\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1cb99364",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 5;\n",
       "                var nbb_unformatted_code = \"from transformers import AutoTokenizer, AutoModelForSequenceClassification\\n\\n# model = AutoModelForSequenceClassification.from_pretrained(\\\"xlm-mlm-100-1280\\\", num_labels=1)\";\n",
       "                var nbb_formatted_code = \"from transformers import AutoTokenizer, AutoModelForSequenceClassification\\n\\n# model = AutoModelForSequenceClassification.from_pretrained(\\\"xlm-mlm-100-1280\\\", num_labels=1)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "# model = AutoModelForSequenceClassification.from_pretrained(\"xlm-mlm-100-1280\", num_labels=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9fa29423",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 6;\n",
       "                var nbb_unformatted_code = \"import torch.nn as nn\\n\\n\\nclass MultiLingualModel(nn.Module):\\n    def __init__(self, model_name):\\n        super().__init__()\\n        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\\n        self.model = AutoModelForSequenceClassification.from_pretrained(\\n            model_name, num_labels=1\\n        ).to(DEVICE)\\n\\n    def forward(self, sentences):\\n        encoded_input = self.tokenizer(\\n            sentences, padding=True, truncation=True, return_tensors=\\\"pt\\\"\\n        ).to(DEVICE)\\n        out = self.model(encoded_input[\\\"input_ids\\\"])\\n        return out\";\n",
       "                var nbb_formatted_code = \"import torch.nn as nn\\n\\n\\nclass MultiLingualModel(nn.Module):\\n    def __init__(self, model_name):\\n        super().__init__()\\n        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\\n        self.model = AutoModelForSequenceClassification.from_pretrained(\\n            model_name, num_labels=1\\n        ).to(DEVICE)\\n\\n    def forward(self, sentences):\\n        encoded_input = self.tokenizer(\\n            sentences, padding=True, truncation=True, return_tensors=\\\"pt\\\"\\n        ).to(DEVICE)\\n        out = self.model(encoded_input[\\\"input_ids\\\"])\\n        return out\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class MultiLingualModel(nn.Module):\n",
    "    def __init__(self, model_name):\n",
    "        super().__init__()\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        self.model = AutoModelForSequenceClassification.from_pretrained(\n",
    "            model_name, num_labels=1\n",
    "        ).to(DEVICE)\n",
    "\n",
    "    def forward(self, sentences):\n",
    "        encoded_input = self.tokenizer(\n",
    "            sentences, padding=True, truncation=True, return_tensors=\"pt\"\n",
    "        ).to(DEVICE)\n",
    "        out = self.model(encoded_input[\"input_ids\"])\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b8d18480",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at cardiffnlp/twitter-xlm-roberta-base were not used when initializing XLMRobertaForSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.decoder.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.bias']\n",
      "- This IS expected if you are initializing XLMRobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at cardiffnlp/twitter-xlm-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 7;\n",
       "                var nbb_unformatted_code = \"model = MultiLingualModel(\\\"cardiffnlp/twitter-xlm-roberta-base\\\")\";\n",
       "                var nbb_formatted_code = \"model = MultiLingualModel(\\\"cardiffnlp/twitter-xlm-roberta-base\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = MultiLingualModel(\"cardiffnlp/twitter-xlm-roberta-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4ef5aaa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 8;\n",
       "                var nbb_unformatted_code = \"out = model([\\\"Wikipedia was used to\\\", \\\"This is great\\\"])\";\n",
       "                var nbb_formatted_code = \"out = model([\\\"Wikipedia was used to\\\", \\\"This is great\\\"])\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "out = model([\"Wikipedia was used to\", \"This is great\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "17be1558",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 9;\n",
       "                var nbb_unformatted_code = \"del out\";\n",
       "                var nbb_formatted_code = \"del out\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "del out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6555f950",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 10;\n",
       "                var nbb_unformatted_code = \"with torch.cuda.device(\\\"cuda:1\\\"):\\n    torch.cuda.empty_cache()\";\n",
       "                var nbb_formatted_code = \"with torch.cuda.device(\\\"cuda:1\\\"):\\n    torch.cuda.empty_cache()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with torch.cuda.device(\"cuda:1\"):\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4a8979c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 11;\n",
       "                var nbb_unformatted_code = \"import pandas as pd\\n\\ndata = pd.read_csv(\\\"data/train.csv\\\")\";\n",
       "                var nbb_formatted_code = \"import pandas as pd\\n\\ndata = pd.read_csv(\\\"data/train.csv\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(\"data/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9ddb457c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 18;\n",
       "                var nbb_unformatted_code = \"def get_data_loader(data, batch_size=16):\\n    shuffled_data = data.sample(frac=1, random_state=0).reset_index(drop=True)\\n    start = 0\\n    end = start + batch_size\\n    data_len = len(shuffled_data)\\n    while start < data_len:\\n        sub_data = shuffled_data[start:end]\\n        start += batch_size\\n        end = min(start + batch_size, data_len)\\n        yield sub_data[\\\"text\\\"].tolist(), torch.tensor(sub_data[\\\"label\\\"].tolist())\";\n",
       "                var nbb_formatted_code = \"def get_data_loader(data, batch_size=16):\\n    shuffled_data = data.sample(frac=1, random_state=0).reset_index(drop=True)\\n    start = 0\\n    end = start + batch_size\\n    data_len = len(shuffled_data)\\n    while start < data_len:\\n        sub_data = shuffled_data[start:end]\\n        start += batch_size\\n        end = min(start + batch_size, data_len)\\n        yield sub_data[\\\"text\\\"].tolist(), torch.tensor(sub_data[\\\"label\\\"].tolist())\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_data_loader(data, batch_size=16):\n",
    "    shuffled_data = data.sample(frac=1, random_state=0).reset_index(drop=True)\n",
    "    start = 0\n",
    "    end = start + batch_size\n",
    "    data_len = len(shuffled_data)\n",
    "    while start < data_len:\n",
    "        sub_data = shuffled_data[start:end]\n",
    "        start += batch_size\n",
    "        end = min(start + batch_size, data_len)\n",
    "        yield sub_data[\"text\"].tolist(), torch.tensor(sub_data[\"label\"].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aef2b505",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 13;\n",
       "                var nbb_unformatted_code = \"from sklearn.model_selection import train_test_split\\n\\ntrain_data, valid_data = train_test_split(\\n    data, test_size=0.2, shuffle=True, random_state=0\\n)\";\n",
       "                var nbb_formatted_code = \"from sklearn.model_selection import train_test_split\\n\\ntrain_data, valid_data = train_test_split(\\n    data, test_size=0.2, shuffle=True, random_state=0\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_data, valid_data = train_test_split(\n",
    "    data, test_size=0.2, shuffle=True, random_state=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "186e6ca7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 47;\n",
       "                var nbb_unformatted_code = \"from tqdm import tqdm\\n\\n\\ndef train_or_valid(model_args, curr_epoch, model, is_train=True):\\n    \\\"\\\"\\\"\\n    This fn. is used to train or validate the model\\n    params:\\n        model_args: a dict of model parameters\\n        curr_epoch: Current value of the epoch\\n        model: model to be trained\\n        is_train: can be True or False depending on whether to train or validate\\n\\n    returns:\\n        loss: sum of the loss across all tokens\\n\\n    \\\"\\\"\\\"\\n    loss_list = []\\n    y_pred_list = []\\n    y_list = []\\n    model_args[\\\"optimizer\\\"].zero_grad()\\n    if is_train:\\n        data_loader = get_data_loader(train_data)\\n        model.train()\\n    else:\\n        data_loader = get_data_loader(valid_data)\\n        model.eval()\\n\\n    with tqdm(data_loader, unit=\\\"batch\\\") as tepoch:\\n        tepoch.set_description(f\\\"Epoch {curr_epoch}\\\")\\n        for step, batch in enumerate(tepoch):\\n            X = batch[0]\\n            y = batch[1].float().to(DEVICE)\\n            y_pred = model(X)\\n            y_pred_list.extend(y_pred[\\\"logits\\\"].tolist())\\n            y_list.extend(y.tolist())\\n            loss = model_args[\\\"criterion\\\"](y_pred[\\\"logits\\\"].reshape(-1), y)\\n            loss_list.append(loss.item())\\n            if is_train:\\n                model_args[\\\"optimizer\\\"].zero_grad()\\n                loss.backward()\\n                nn.utils.clip_grad_norm_(model.parameters(), 2)\\n                model_args[\\\"optimizer\\\"].step()\\n            tepoch.set_postfix(loss=loss.item())\\n\\n    return sum(loss_list), y_pred, y_list\";\n",
       "                var nbb_formatted_code = \"from tqdm import tqdm\\n\\n\\ndef train_or_valid(model_args, curr_epoch, model, is_train=True):\\n    \\\"\\\"\\\"\\n    This fn. is used to train or validate the model\\n    params:\\n        model_args: a dict of model parameters\\n        curr_epoch: Current value of the epoch\\n        model: model to be trained\\n        is_train: can be True or False depending on whether to train or validate\\n\\n    returns:\\n        loss: sum of the loss across all tokens\\n\\n    \\\"\\\"\\\"\\n    loss_list = []\\n    y_pred_list = []\\n    y_list = []\\n    model_args[\\\"optimizer\\\"].zero_grad()\\n    if is_train:\\n        data_loader = get_data_loader(train_data)\\n        model.train()\\n    else:\\n        data_loader = get_data_loader(valid_data)\\n        model.eval()\\n\\n    with tqdm(data_loader, unit=\\\"batch\\\") as tepoch:\\n        tepoch.set_description(f\\\"Epoch {curr_epoch}\\\")\\n        for step, batch in enumerate(tepoch):\\n            X = batch[0]\\n            y = batch[1].float().to(DEVICE)\\n            y_pred = model(X)\\n            y_pred_list.extend(y_pred[\\\"logits\\\"].tolist())\\n            y_list.extend(y.tolist())\\n            loss = model_args[\\\"criterion\\\"](y_pred[\\\"logits\\\"].reshape(-1), y)\\n            loss_list.append(loss.item())\\n            if is_train:\\n                model_args[\\\"optimizer\\\"].zero_grad()\\n                loss.backward()\\n                nn.utils.clip_grad_norm_(model.parameters(), 2)\\n                model_args[\\\"optimizer\\\"].step()\\n            tepoch.set_postfix(loss=loss.item())\\n\\n    return sum(loss_list), y_pred, y_list\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def train_or_valid(model_args, curr_epoch, model, is_train=True):\n",
    "    \"\"\"\n",
    "    This fn. is used to train or validate the model\n",
    "    params:\n",
    "        model_args: a dict of model parameters\n",
    "        curr_epoch: Current value of the epoch\n",
    "        model: model to be trained\n",
    "        is_train: can be True or False depending on whether to train or validate\n",
    "\n",
    "    returns:\n",
    "        loss: sum of the loss across all tokens\n",
    "\n",
    "    \"\"\"\n",
    "    loss_list = []\n",
    "    y_pred_list = []\n",
    "    y_list = []\n",
    "    model_args[\"optimizer\"].zero_grad()\n",
    "    if is_train:\n",
    "        data_loader = get_data_loader(train_data)\n",
    "        model.train()\n",
    "    else:\n",
    "        data_loader = get_data_loader(valid_data)\n",
    "        model.eval()\n",
    "\n",
    "    with tqdm(data_loader, unit=\"batch\") as tepoch:\n",
    "        tepoch.set_description(f\"Epoch {curr_epoch}\")\n",
    "        for step, batch in enumerate(tepoch):\n",
    "            X = batch[0]\n",
    "            y = batch[1].float().to(DEVICE)\n",
    "            y_pred = model(X)\n",
    "            y_pred_list.extend(y_pred[\"logits\"].tolist())\n",
    "            y_list.extend(y.tolist())\n",
    "            loss = model_args[\"criterion\"](y_pred[\"logits\"].reshape(-1), y)\n",
    "            loss_list.append(loss.item())\n",
    "            if is_train:\n",
    "                model_args[\"optimizer\"].zero_grad()\n",
    "                loss.backward()\n",
    "                nn.utils.clip_grad_norm_(model.parameters(), 2)\n",
    "                model_args[\"optimizer\"].step()\n",
    "            tepoch.set_postfix(loss=loss.item())\n",
    "\n",
    "    return sum(loss_list), y_pred, y_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d4828b91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 48;\n",
       "                var nbb_unformatted_code = \"# Defining parameters for the model\\ndef get_model_args():\\n    # returns a dict - {param: value}\\n    return {\\n        \\\"batch_size\\\": 16,\\n        \\\"epoch\\\": 15,\\n        \\\"learning_rate\\\": 0.001,\\n    }\";\n",
       "                var nbb_formatted_code = \"# Defining parameters for the model\\ndef get_model_args():\\n    # returns a dict - {param: value}\\n    return {\\n        \\\"batch_size\\\": 16,\\n        \\\"epoch\\\": 15,\\n        \\\"learning_rate\\\": 0.001,\\n    }\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Defining parameters for the model\n",
    "def get_model_args():\n",
    "    # returns a dict - {param: value}\n",
    "    return {\n",
    "        \"batch_size\": 16,\n",
    "        \"epoch\": 15,\n",
    "        \"learning_rate\": 0.001,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "59b31b3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 49;\n",
       "                var nbb_unformatted_code = \"import numpy as np\\n\\n\\ndef compute_r(y, y_pred):\\n    corr = np.corrcoef(y, y_pred)\\n    return corr\";\n",
       "                var nbb_formatted_code = \"import numpy as np\\n\\n\\ndef compute_r(y, y_pred):\\n    corr = np.corrcoef(y, y_pred)\\n    return corr\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def compute_r(y, y_pred):\n",
    "    corr = np.corrcoef(y, y_pred)\n",
    "    return corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "eea415f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0: : 475batch [00:55,  8.59batch/s, loss=0.542]\n",
      "Epoch 0: : 119batch [00:01, 59.66batch/s, loss=0.636]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "all the input array dimensions for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 1 and the array at index 1 has size 1899",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [51]\u001b[0m, in \u001b[0;36m<cell line: 15>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# validate the model\u001b[39;00m\n\u001b[1;32m     22\u001b[0m valid_loss, valid_y_pred, valid_y \u001b[38;5;241m=\u001b[39m train_or_valid(\n\u001b[1;32m     23\u001b[0m     model_args, epoch, model, \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     24\u001b[0m )\n\u001b[0;32m---> 25\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPearson\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms r is : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcompute_r(valid_y_pred, valid_y)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     26\u001b[0m epoch_valid_loss\u001b[38;5;241m.\u001b[39mappend(valid_loss)\n\u001b[1;32m     27\u001b[0m epoch_valid_r\u001b[38;5;241m.\u001b[39mappend(compute_r)\n",
      "Input \u001b[0;32mIn [49]\u001b[0m, in \u001b[0;36mcompute_r\u001b[0;34m(y, y_pred)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_r\u001b[39m(y, y_pred):\n\u001b[0;32m----> 5\u001b[0m     corr \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcorrcoef\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m corr\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mcorrcoef\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/conda/envs/nlp_env/lib/python3.10/site-packages/numpy/lib/function_base.py:2845\u001b[0m, in \u001b[0;36mcorrcoef\u001b[0;34m(x, y, rowvar, bias, ddof, dtype)\u001b[0m\n\u001b[1;32m   2841\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m bias \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39m_NoValue \u001b[38;5;129;01mor\u001b[39;00m ddof \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39m_NoValue:\n\u001b[1;32m   2842\u001b[0m     \u001b[38;5;66;03m# 2015-03-15, 1.10\u001b[39;00m\n\u001b[1;32m   2843\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbias and ddof have no effect and are deprecated\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   2844\u001b[0m                   \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\n\u001b[0;32m-> 2845\u001b[0m c \u001b[38;5;241m=\u001b[39m \u001b[43mcov\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrowvar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2846\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   2847\u001b[0m     d \u001b[38;5;241m=\u001b[39m diag(c)\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mcov\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/conda/envs/nlp_env/lib/python3.10/site-packages/numpy/lib/function_base.py:2639\u001b[0m, in \u001b[0;36mcov\u001b[0;34m(m, y, rowvar, bias, ddof, fweights, aweights, dtype)\u001b[0m\n\u001b[1;32m   2637\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m rowvar \u001b[38;5;129;01mand\u001b[39;00m y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   2638\u001b[0m         y \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39mT\n\u001b[0;32m-> 2639\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2641\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ddof \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2642\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m bias \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mconcatenate\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: all the input array dimensions for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 1 and the array at index 1 has size 1899"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 51;\n",
       "                var nbb_unformatted_code = \"import time\\n\\nmodel_args = get_model_args()\\n# Loss and Optimization\\nmodel_args[\\\"criterion\\\"] = nn.MSELoss()\\nmodel_args[\\\"optimizer\\\"] = torch.optim.Adam(\\n    model.model.parameters(), lr=model_args[\\\"learning_rate\\\"]\\n)\\n\\n# Log Metrics\\nepoch_train_loss = []\\nepoch_valid_loss = []\\nepoch_valid_r = []\\n# Begin Training\\nfor epoch in range(model_args[\\\"epoch\\\"]):\\n\\n    # Train the model\\n    train_loss, _, _ = train_or_valid(model_args, epoch, model)\\n    epoch_train_loss.append(train_loss)\\n\\n    # validate the model\\n    valid_loss, valid_y_pred, valid_y = train_or_valid(\\n        model_args, epoch, model, False\\n    )\\n    print(f\\\"Pearson's r is : {compute_r(valid_y_pred, valid_y)}\\\")\\n    epoch_valid_loss.append(valid_loss)\\n    epoch_valid_r.append(compute_r)\";\n",
       "                var nbb_formatted_code = \"import time\\n\\nmodel_args = get_model_args()\\n# Loss and Optimization\\nmodel_args[\\\"criterion\\\"] = nn.MSELoss()\\nmodel_args[\\\"optimizer\\\"] = torch.optim.Adam(\\n    model.model.parameters(), lr=model_args[\\\"learning_rate\\\"]\\n)\\n\\n# Log Metrics\\nepoch_train_loss = []\\nepoch_valid_loss = []\\nepoch_valid_r = []\\n# Begin Training\\nfor epoch in range(model_args[\\\"epoch\\\"]):\\n\\n    # Train the model\\n    train_loss, _, _ = train_or_valid(model_args, epoch, model)\\n    epoch_train_loss.append(train_loss)\\n\\n    # validate the model\\n    valid_loss, valid_y_pred, valid_y = train_or_valid(model_args, epoch, model, False)\\n    print(f\\\"Pearson's r is : {compute_r(valid_y_pred, valid_y)}\\\")\\n    epoch_valid_loss.append(valid_loss)\\n    epoch_valid_r.append(compute_r)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "model_args = get_model_args()\n",
    "# Loss and Optimization\n",
    "model_args[\"criterion\"] = nn.MSELoss()\n",
    "model_args[\"optimizer\"] = torch.optim.Adam(\n",
    "    model.model.parameters(), lr=model_args[\"learning_rate\"]\n",
    ")\n",
    "\n",
    "# Log Metrics\n",
    "epoch_train_loss = []\n",
    "epoch_valid_loss = []\n",
    "epoch_valid_r = []\n",
    "# Begin Training\n",
    "for epoch in range(model_args[\"epoch\"]):\n",
    "\n",
    "    # Train the model\n",
    "    train_loss, _, _ = train_or_valid(model_args, epoch, model)\n",
    "    epoch_train_loss.append(train_loss)\n",
    "\n",
    "    # validate the model\n",
    "    valid_loss, valid_y_pred, valid_y = train_or_valid(model_args, epoch, model, False)\n",
    "    print(f\"Pearson's r is : {compute_r(valid_y_pred, valid_y)}\")\n",
    "    epoch_valid_loss.append(valid_loss)\n",
    "    epoch_valid_r.append(compute_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dd1d2358",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>wearing a fake engagement ring so guys won‚Äôt a...</td>\n",
       "      <td>1.8</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bees vs. Wasps. http</td>\n",
       "      <td>1.0</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Here is a nice equation: 0+0-0-0+0=0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@user @user Enjoy each new day!üòäüá®üá¶üêûüê≠</td>\n",
       "      <td>1.6</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I can be having a perfectly good day then I th...</td>\n",
       "      <td>1.6</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label language\n",
       "0  wearing a fake engagement ring so guys won‚Äôt a...    1.8  English\n",
       "1                               Bees vs. Wasps. http    1.0  English\n",
       "2               Here is a nice equation: 0+0-0-0+0=0    1.0  English\n",
       "3               @user @user Enjoy each new day!üòäüá®üá¶üêûüê≠    1.6  English\n",
       "4  I can be having a perfectly good day then I th...    1.6  English"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 18;\n",
       "                var nbb_unformatted_code = \"data.head()\";\n",
       "                var nbb_formatted_code = \"data.head()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4687238d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequenceClassifierOutput(loss=None, logits=tensor([[2.3468]], device='cuda:1', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 23;\n",
       "                var nbb_unformatted_code = \"model (\\\"Here is a nice equation: 0+0-0-0+0=0\\\")\";\n",
       "                var nbb_formatted_code = \"model(\\\"Here is a nice equation: 0+0-0-0+0=0\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model(\"Here is a nice equation: 0+0-0-0+0=0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ebd265",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f8203e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"import time\n",
    "\n",
    "total_loss = []\n",
    "model.model.train()\n",
    "for epoch in range(5):\n",
    "    epoch_loss = []\n",
    "    train_data = data_loader(data)\n",
    "    for X, y in train_data:\n",
    "\n",
    "        y = y.float().to(DEVICE)\n",
    "        y_pred = model(X)\n",
    "        loss = mse_loss(y_pred[\"logits\"].reshape(-1), y)\n",
    "        optimizer.zero_grad()\n",
    "        epoch_loss.append(loss.item())\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.model.parameters(), 1)\n",
    "        optimizer.step()\n",
    "        del X, y, y_pred, loss\n",
    "        # del y, y_pred, loss\n",
    "        import gc\n",
    "\n",
    "        gc.collect()\n",
    "        with torch.cuda.device(DEVICE):\n",
    "            torch.cuda.empty_cache()\n",
    "    total_loss.append(sum(epoch_loss) / len(epoch_loss))\n",
    "    print(total_loss)\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
