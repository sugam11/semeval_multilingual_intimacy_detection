{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f58533",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext nb_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce3233e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.manual_seed(0)\n",
    "torch.use_deterministic_algorithms(False)\n",
    "\n",
    "import random\n",
    "random.seed(0)\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb0c6c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    dev = \"cuda:1\"\n",
    "else:\n",
    "    dev = \"cpu\"\n",
    "DEVICE = torch.device(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "579ddd2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 4;\n",
       "                var nbb_unformatted_code = \"import torch\\nfrom transformers import XLMTokenizer, XLMWithLMHeadModel\\n\\n# tokenizer = XLMTokenizer.from_pretrained(\\\"xlm-mlm-100-1280\\\")\\n# model = XLMWithLMHeadModel.from_pretrained(\\\"xlm-mlm-100-1280\\\")\";\n",
       "                var nbb_formatted_code = \"import torch\\nfrom transformers import XLMTokenizer, XLMWithLMHeadModel\\n\\n# tokenizer = XLMTokenizer.from_pretrained(\\\"xlm-mlm-100-1280\\\")\\n# model = XLMWithLMHeadModel.from_pretrained(\\\"xlm-mlm-100-1280\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import XLMTokenizer, XLMWithLMHeadModel\n",
    "\n",
    "# tokenizer = XLMTokenizer.from_pretrained(\"xlm-mlm-100-1280\")\n",
    "# model = XLMWithLMHeadModel.from_pretrained(\"xlm-mlm-100-1280\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1cb99364",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 5;\n",
       "                var nbb_unformatted_code = \"from transformers import AutoTokenizer, AutoModelForSequenceClassification\\n\\n# model = AutoModelForSequenceClassification.from_pretrained(\\\"xlm-mlm-100-1280\\\", num_labels=1)\";\n",
       "                var nbb_formatted_code = \"from transformers import AutoTokenizer, AutoModelForSequenceClassification\\n\\n# model = AutoModelForSequenceClassification.from_pretrained(\\\"xlm-mlm-100-1280\\\", num_labels=1)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "# model = AutoModelForSequenceClassification.from_pretrained(\"xlm-mlm-100-1280\", num_labels=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9fa29423",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 28;\n",
       "                var nbb_unformatted_code = \"import torch.nn as nn\\n\\n\\nclass MultiLingualModel(nn.Module):\\n    def __init__(self, model_name):\\n        super().__init__()\\n        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\\n        self.model = AutoModelForSequenceClassification.from_pretrained(\\n            model_name, num_labels=1\\n        ).to(DEVICE)\\n\\n    def forward(self, sentences):\\n        encoded_input = self.tokenizer(\\n            sentences, padding=True, truncation=True, return_tensors=\\\"pt\\\"\\n        ).to(DEVICE)\\n        out = self.model(encoded_input[\\\"input_ids\\\"])\\n        return out\";\n",
       "                var nbb_formatted_code = \"import torch.nn as nn\\n\\n\\nclass MultiLingualModel(nn.Module):\\n    def __init__(self, model_name):\\n        super().__init__()\\n        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\\n        self.model = AutoModelForSequenceClassification.from_pretrained(\\n            model_name, num_labels=1\\n        ).to(DEVICE)\\n\\n    def forward(self, sentences):\\n        encoded_input = self.tokenizer(\\n            sentences, padding=True, truncation=True, return_tensors=\\\"pt\\\"\\n        ).to(DEVICE)\\n        out = self.model(encoded_input[\\\"input_ids\\\"])\\n        return out\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class MultiLingualModel(nn.Module):\n",
    "    def __init__(self, model_name):\n",
    "        super().__init__()\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        self.model = AutoModelForSequenceClassification.from_pretrained(\n",
    "            model_name, num_labels=1\n",
    "        ).to(DEVICE)\n",
    "\n",
    "    def forward(self, sentences):\n",
    "        encoded_input = self.tokenizer(\n",
    "            sentences, padding=True, truncation=True, return_tensors=\"pt\"\n",
    "        ).to(DEVICE)\n",
    "        out = self.model(encoded_input[\"input_ids\"])\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b8d18480",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at cardiffnlp/twitter-xlm-roberta-base were not used when initializing XLMRobertaForSequenceClassification: ['lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.decoder.bias', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.bias']\n",
      "- This IS expected if you are initializing XLMRobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at cardiffnlp/twitter-xlm-roberta-base and are newly initialized: ['classifier.out_proj.bias', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 29;\n",
       "                var nbb_unformatted_code = \"model = MultiLingualModel(\\\"cardiffnlp/twitter-xlm-roberta-base\\\")\";\n",
       "                var nbb_formatted_code = \"model = MultiLingualModel(\\\"cardiffnlp/twitter-xlm-roberta-base\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = MultiLingualModel(\"cardiffnlp/twitter-xlm-roberta-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4ef5aaa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 30;\n",
       "                var nbb_unformatted_code = \"out = model([\\\"Wikipedia was used to\\\", \\\"This is great\\\"])\";\n",
       "                var nbb_formatted_code = \"out = model([\\\"Wikipedia was used to\\\", \\\"This is great\\\"])\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "out = model([\"Wikipedia was used to\", \"This is great\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ea2df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "del out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "612063cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.cuda.device(\"cuda:1\"):\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a8979c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(\"data/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ddb457c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_loader(data, batch_size=16):\n",
    "    shuffled_data = data.sample(frac=1, random_state=0).reset_index(drop=True)\n",
    "    start = 0\n",
    "    end = start + batch_size\n",
    "    data_len = len(shuffled_data)\n",
    "    while start < data_len:\n",
    "        sub_data = shuffled_data[start:end]\n",
    "        start += batch_size\n",
    "        end = min(start + batch_size, data_len)\n",
    "        yield sub_data[\"text\"].tolist(), torch.tensor(sub_data[\"label\"].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f05575b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_data, valid_data = train_test_split(\n",
    "    data, test_size=0.2, shuffle=True, random_state=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe00ef97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def train_or_valid(model_args, curr_epoch, model, is_train=True):\n",
    "    \"\"\"\n",
    "    This fn. is used to train or validate the model\n",
    "    params:\n",
    "        model_args: a dict of model parameters\n",
    "        curr_epoch: Current value of the epoch\n",
    "        model: model to be trained\n",
    "        is_train: can be True or False depending on whether to train or validate\n",
    "\n",
    "    returns:\n",
    "        loss: sum of the loss across all tokens\n",
    "\n",
    "    \"\"\"\n",
    "    loss_list = []\n",
    "    y_pred_list = []\n",
    "    y_list = []\n",
    "    model_args[\"optimizer\"].zero_grad()\n",
    "    if is_train:\n",
    "        data_loader = get_data_loader(train_data, batch_size=24)\n",
    "        model.train()\n",
    "    else:\n",
    "        data_loader = get_data_loader(valid_data)\n",
    "        model.eval()\n",
    "\n",
    "    with tqdm(data_loader, unit=\"batch\") as tepoch:\n",
    "        tepoch.set_description(f\"Epoch {curr_epoch}\")\n",
    "        for step, batch in enumerate(tepoch):\n",
    "            X = batch[0]\n",
    "            y = batch[1].float().to(DEVICE)\n",
    "            y_pred = model(X)\n",
    "            y_pred_list.extend(y_pred[\"logits\"].reshape(-1).tolist())\n",
    "            y_list.extend(y.tolist())\n",
    "            loss = model_args[\"criterion\"](y_pred[\"logits\"].reshape(-1), y)\n",
    "            loss_list.append(loss.item())\n",
    "            if is_train:\n",
    "                model_args[\"optimizer\"].zero_grad()\n",
    "                loss.backward()\n",
    "                nn.utils.clip_grad_norm_(model.parameters(), 2)\n",
    "                model_args[\"optimizer\"].step()\n",
    "            tepoch.set_postfix(loss=loss.item())\n",
    "    if is_train is False:\n",
    "        valid_data[f\"y_pred_{curr_epoch}\"] = y_pred_list\n",
    "    else:\n",
    "        train_data[f\"y_pred_{curr_epoch}\"] = y_pred_list\n",
    "    return sum(loss_list), y_pred_list, y_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd559183",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining parameters for the model\n",
    "def get_model_args():\n",
    "    # returns a dict - {param: value}\n",
    "    return {\n",
    "        \"batch_size\": 16,\n",
    "        \"epoch\": 2,\n",
    "        \"learning_rate\": 0.001,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4713c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "\n",
    "\"\"\"\n",
    "    https://numpy.org/doc/stable/reference/generated/numpy.corrcoef.html\n",
    "    \n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def compute_r(y, y_pred):\n",
    "    # corr = np.corrcoef(y, y_pred)\n",
    "    corr = scipy.stats.pearsonr(y, y_pred)\n",
    "    return corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e01678b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model(\"je suis japonaise câ€™est officiel ðŸ¥´\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a0b2e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "model = MultiLingualModel(\"cardiffnlp/twitter-xlm-roberta-base\")\n",
    "model_args = get_model_args()\n",
    "# Loss and Optimization\n",
    "model_args[\"criterion\"] = nn.MSELoss()\n",
    "model_args[\"optimizer\"] = torch.optim.AdamW(\n",
    "    model.model.parameters(), lr=model_args[\"learning_rate\"]\n",
    ")\n",
    "\n",
    "# Log Metrics\n",
    "epoch_train_loss = []\n",
    "epoch_valid_loss = []\n",
    "epoch_valid_r = []\n",
    "# Begin Training\n",
    "for epoch in range(model_args[\"epoch\"]):\n",
    "\n",
    "    # Train the model\n",
    "    train_loss, _, _ = train_or_valid(model_args, epoch, model)\n",
    "    epoch_train_loss.append(train_loss)\n",
    "    print(model(\"je suis japonaise câ€™est officiel ðŸ¥´\"))\n",
    "    # validate the model\n",
    "    valid_loss, valid_y_pred, valid_y = train_or_valid(model_args, epoch, model, False)\n",
    "    # print(f\"Pearson's r is : {compute_r(valid_y_pred, valid_y)}\")\n",
    "    compute_language_correlation(valid_data, epoch)\n",
    "    epoch_valid_loss.append(valid_loss)\n",
    "    epoch_valid_r.append(compute_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e66d93e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_language_correlation(valid_data, epoch):\n",
    "    for language in valid_data[\"language\"].unique():\n",
    "        r = compute_r(\n",
    "            valid_data[valid_data[\"language\"] == language][f\"y_pred_{epoch}\"],\n",
    "            valid_data[valid_data[\"language\"] == language][\"label\"],\n",
    "        )\n",
    "        print(f\"correlation for {language} is : {r}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b533cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model(\"je suis japonaise câ€™est officiel ðŸ¥´\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac3af789",
   "metadata": {},
   "outputs": [],
   "source": [
    "model(\"Posting some VIP client tickets: http\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e795356d",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_data.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69246402",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f8203e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"import time\n",
    "\n",
    "total_loss = []\n",
    "model.model.train()\n",
    "for epoch in range(5):\n",
    "    epoch_loss = []\n",
    "    train_data = data_loader(data)\n",
    "    for X, y in train_data:\n",
    "\n",
    "        y = y.float().to(DEVICE)\n",
    "        y_pred = model(X)\n",
    "        loss = mse_loss(y_pred[\"logits\"].reshape(-1), y)\n",
    "        optimizer.zero_grad()\n",
    "        epoch_loss.append(loss.item())\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.model.parameters(), 1)\n",
    "        optimizer.step()\n",
    "        del X, y, y_pred, loss\n",
    "        # del y, y_pred, loss\n",
    "        import gc\n",
    "\n",
    "        gc.collect()\n",
    "        with torch.cuda.device(DEVICE):\n",
    "            torch.cuda.empty_cache()\n",
    "    total_loss.append(sum(epoch_loss) / len(epoch_loss))\n",
    "    print(total_loss)\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
