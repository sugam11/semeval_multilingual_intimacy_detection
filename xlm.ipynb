{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "09f58533",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 1;\n",
       "                var nbb_unformatted_code = \"%load_ext nb_black\";\n",
       "                var nbb_formatted_code = \"%load_ext nb_black\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext nb_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ce3233e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2;\n",
       "                var nbb_unformatted_code = \"import torch\\ntorch.manual_seed(0)\\ntorch.use_deterministic_algorithms(False)\\n\\nimport random\\nrandom.seed(0)\\n\\nimport numpy as np\\nnp.random.seed(0)\";\n",
       "                var nbb_formatted_code = \"import torch\\n\\ntorch.manual_seed(0)\\ntorch.use_deterministic_algorithms(False)\\n\\nimport random\\n\\nrandom.seed(0)\\n\\nimport numpy as np\\n\\nnp.random.seed(0)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "torch.manual_seed(0)\n",
    "torch.use_deterministic_algorithms(False)\n",
    "\n",
    "import random\n",
    "random.seed(0)\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6eb0c6c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 3;\n",
       "                var nbb_unformatted_code = \"if torch.cuda.is_available():\\n    dev = \\\"cuda:1\\\"\\nelse:\\n    dev = \\\"cpu\\\"\\nDEVICE = torch.device(dev)\";\n",
       "                var nbb_formatted_code = \"if torch.cuda.is_available():\\n    dev = \\\"cuda:1\\\"\\nelse:\\n    dev = \\\"cpu\\\"\\nDEVICE = torch.device(dev)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    dev = \"cuda:1\"\n",
    "else:\n",
    "    dev = \"cpu\"\n",
    "DEVICE = torch.device(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "579ddd2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 4;\n",
       "                var nbb_unformatted_code = \"import torch\\nfrom transformers import XLMTokenizer, XLMWithLMHeadModel\\n\\n# tokenizer = XLMTokenizer.from_pretrained(\\\"xlm-mlm-100-1280\\\")\\n# model = XLMWithLMHeadModel.from_pretrained(\\\"xlm-mlm-100-1280\\\")\";\n",
       "                var nbb_formatted_code = \"import torch\\nfrom transformers import XLMTokenizer, XLMWithLMHeadModel\\n\\n# tokenizer = XLMTokenizer.from_pretrained(\\\"xlm-mlm-100-1280\\\")\\n# model = XLMWithLMHeadModel.from_pretrained(\\\"xlm-mlm-100-1280\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import XLMTokenizer, XLMWithLMHeadModel\n",
    "\n",
    "# tokenizer = XLMTokenizer.from_pretrained(\"xlm-mlm-100-1280\")\n",
    "# model = XLMWithLMHeadModel.from_pretrained(\"xlm-mlm-100-1280\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1cb99364",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 5;\n",
       "                var nbb_unformatted_code = \"from transformers import AutoTokenizer, AutoModelForSequenceClassification\\n\\n# model = AutoModelForSequenceClassification.from_pretrained(\\\"xlm-mlm-100-1280\\\", num_labels=1)\";\n",
       "                var nbb_formatted_code = \"from transformers import AutoTokenizer, AutoModelForSequenceClassification\\n\\n# model = AutoModelForSequenceClassification.from_pretrained(\\\"xlm-mlm-100-1280\\\", num_labels=1)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "# model = AutoModelForSequenceClassification.from_pretrained(\"xlm-mlm-100-1280\", num_labels=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9fa29423",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 6;\n",
       "                var nbb_unformatted_code = \"import torch.nn as nn\\nfrom transformers import XLMRobertaModel\\n\\n\\nclass MultiLingualModel(nn.Module):\\n    def __init__(self, model_name):\\n        super().__init__()\\n        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\\n        self.model = XLMRobertaModel.from_pretrained(\\n            model_name, output_attentions=False, output_hidden_states=False\\n        ).to(DEVICE)\\n        self.regressor = nn.Sequential(nn.Dropout(0.2), nn.Linear(768, 1)).to(DEVICE)\\n\\n    def forward(self, sentences):\\n        encoded_input = self.tokenizer(\\n            sentences, padding=True, truncation=True, return_tensors=\\\"pt\\\"\\n        ).to(DEVICE)\\n        out = self.model(**encoded_input)[1]\\n        out = self.regressor(out)\\n        return out, encoded_input\";\n",
       "                var nbb_formatted_code = \"import torch.nn as nn\\nfrom transformers import XLMRobertaModel\\n\\n\\nclass MultiLingualModel(nn.Module):\\n    def __init__(self, model_name):\\n        super().__init__()\\n        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\\n        self.model = XLMRobertaModel.from_pretrained(\\n            model_name, output_attentions=False, output_hidden_states=False\\n        ).to(DEVICE)\\n        self.regressor = nn.Sequential(nn.Dropout(0.2), nn.Linear(768, 1)).to(DEVICE)\\n\\n    def forward(self, sentences):\\n        encoded_input = self.tokenizer(\\n            sentences, padding=True, truncation=True, return_tensors=\\\"pt\\\"\\n        ).to(DEVICE)\\n        out = self.model(**encoded_input)[1]\\n        out = self.regressor(out)\\n        return out, encoded_input\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "from transformers import XLMRobertaModel\n",
    "\n",
    "\n",
    "class MultiLingualModel(nn.Module):\n",
    "    def __init__(self, model_name):\n",
    "        super().__init__()\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        self.model = XLMRobertaModel.from_pretrained(\n",
    "            model_name, output_attentions=False, output_hidden_states=False\n",
    "        ).to(DEVICE)\n",
    "        self.regressor = nn.Sequential(nn.Dropout(0.2), nn.Linear(768, 1)).to(DEVICE)\n",
    "\n",
    "    def forward(self, sentences):\n",
    "        encoded_input = self.tokenizer(\n",
    "            sentences, padding=True, truncation=True, return_tensors=\"pt\"\n",
    "        ).to(DEVICE)\n",
    "        out = self.model(**encoded_input)[1]\n",
    "        out = self.regressor(out)\n",
    "        return out, encoded_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b8d18480",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at cardiffnlp/twitter-xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.decoder.bias', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.bias']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of XLMRobertaModel were not initialized from the model checkpoint at cardiffnlp/twitter-xlm-roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 7;\n",
       "                var nbb_unformatted_code = \"model = MultiLingualModel(\\\"cardiffnlp/twitter-xlm-roberta-base\\\")\";\n",
       "                var nbb_formatted_code = \"model = MultiLingualModel(\\\"cardiffnlp/twitter-xlm-roberta-base\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = MultiLingualModel(\"cardiffnlp/twitter-xlm-roberta-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4ef5aaa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 8;\n",
       "                var nbb_unformatted_code = \"out, tokens = model([\\\"Wikipedia was used to\\\", \\\"This is great\\\"])\";\n",
       "                var nbb_formatted_code = \"out, tokens = model([\\\"Wikipedia was used to\\\", \\\"This is great\\\"])\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "out, tokens = model([\"Wikipedia was used to\", \"This is great\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "02d88c55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1352],\n",
       "        [0.0811]], device='cuda:1', grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 9;\n",
       "                var nbb_unformatted_code = \"out\";\n",
       "                var nbb_formatted_code = \"out\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5e0d73a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[    0,  8162,   509, 11814,    47,     2],\n",
       "        [    0,  3293,    83,  6782,     2,     1]], device='cuda:1'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 0]], device='cuda:1')}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 10;\n",
       "                var nbb_unformatted_code = \"tokens\";\n",
       "                var nbb_formatted_code = \"tokens\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e9ea2df3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 11;\n",
       "                var nbb_unformatted_code = \"del out\";\n",
       "                var nbb_formatted_code = \"del out\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "del out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "612063cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 12;\n",
       "                var nbb_unformatted_code = \"with torch.cuda.device(\\\"cuda:1\\\"):\\n    torch.cuda.empty_cache()\";\n",
       "                var nbb_formatted_code = \"with torch.cuda.device(\\\"cuda:1\\\"):\\n    torch.cuda.empty_cache()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with torch.cuda.device(\"cuda:1\"):\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4a8979c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 13;\n",
       "                var nbb_unformatted_code = \"import pandas as pd\\n\\ndata = pd.read_csv(\\\"data/train.csv\\\")\";\n",
       "                var nbb_formatted_code = \"import pandas as pd\\n\\ndata = pd.read_csv(\\\"data/train.csv\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(\"data/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9ddb457c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 14;\n",
       "                var nbb_unformatted_code = \"def get_data_loader(data, batch_size=16):\\n    shuffled_data = data.sample(frac=1, random_state=0).reset_index(drop=True)\\n    start = 0\\n    end = start + batch_size\\n    data_len = len(shuffled_data)\\n    while start < data_len:\\n        sub_data = shuffled_data[start:end]\\n        start += batch_size\\n        end = min(start + batch_size, data_len)\\n        yield sub_data[\\\"text\\\"].tolist(), torch.tensor(sub_data[\\\"label\\\"].tolist())\";\n",
       "                var nbb_formatted_code = \"def get_data_loader(data, batch_size=16):\\n    shuffled_data = data.sample(frac=1, random_state=0).reset_index(drop=True)\\n    start = 0\\n    end = start + batch_size\\n    data_len = len(shuffled_data)\\n    while start < data_len:\\n        sub_data = shuffled_data[start:end]\\n        start += batch_size\\n        end = min(start + batch_size, data_len)\\n        yield sub_data[\\\"text\\\"].tolist(), torch.tensor(sub_data[\\\"label\\\"].tolist())\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_data_loader(data, batch_size=16):\n",
    "    shuffled_data = data.sample(frac=1, random_state=0).reset_index(drop=True)\n",
    "    start = 0\n",
    "    end = start + batch_size\n",
    "    data_len = len(shuffled_data)\n",
    "    while start < data_len:\n",
    "        sub_data = shuffled_data[start:end]\n",
    "        start += batch_size\n",
    "        end = min(start + batch_size, data_len)\n",
    "        yield sub_data[\"text\"].tolist(), torch.tensor(sub_data[\"label\"].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f05575b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 15;\n",
       "                var nbb_unformatted_code = \"from sklearn.model_selection import train_test_split\\n\\ntrain_data, valid_data = train_test_split(\\n    data, test_size=0.2, shuffle=True, random_state=0\\n)\";\n",
       "                var nbb_formatted_code = \"from sklearn.model_selection import train_test_split\\n\\ntrain_data, valid_data = train_test_split(\\n    data, test_size=0.2, shuffle=True, random_state=0\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_data, valid_data = train_test_split(\n",
    "    data, test_size=0.2, shuffle=True, random_state=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fe00ef97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 16;\n",
       "                var nbb_unformatted_code = \"from tqdm import tqdm\\n\\n\\ndef train_or_valid(model_args, curr_epoch, model, is_train=True):\\n    \\\"\\\"\\\"\\n    This fn. is used to train or validate the model\\n    params:\\n        model_args: a dict of model parameters\\n        curr_epoch: Current value of the epoch\\n        model: model to be trained\\n        is_train: can be True or False depending on whether to train or validate\\n\\n    returns:\\n        loss: sum of the loss across all tokens\\n\\n    \\\"\\\"\\\"\\n    loss_list = []\\n    y_pred_list = []\\n    y_list = []\\n    model_args[\\\"optimizer\\\"].zero_grad()\\n    if is_train:\\n        data_loader = get_data_loader(train_data, batch_size=model_args[\\\"batch_size\\\"])\\n        model.train()\\n    else:\\n        data_loader = get_data_loader(valid_data)\\n        model.eval()\\n\\n    with tqdm(data_loader, unit=\\\"batch\\\") as tepoch:\\n        tepoch.set_description(f\\\"Epoch {curr_epoch}\\\")\\n        for step, batch in enumerate(tepoch):\\n            X = batch[0]\\n            y = batch[1].float().to(DEVICE)\\n            y_pred, _ = model(X)\\n            y_pred_list.extend(y_pred.reshape(-1).tolist())\\n            y_list.extend(y.tolist())\\n            loss = model_args[\\\"criterion\\\"](y_pred.reshape(-1), y)\\n            loss_list.append(loss.item())\\n            if is_train:\\n                model_args[\\\"optimizer\\\"].zero_grad()\\n                loss.backward()\\n                nn.utils.clip_grad_norm_(model.parameters(), 2)\\n                model_args[\\\"optimizer\\\"].step()\\n                model_args[\\\"scheduler\\\"].step()\\n            tepoch.set_postfix(loss=sum(loss_list) / len(loss_list))\\n    if is_train is False:\\n        valid_data[f\\\"y_pred_{curr_epoch}\\\"] = y_pred_list\\n    else:\\n        train_data[f\\\"y_pred_{curr_epoch}\\\"] = y_pred_list\\n    return sum(loss_list) / len(loss_list), y_pred_list, y_list\";\n",
       "                var nbb_formatted_code = \"from tqdm import tqdm\\n\\n\\ndef train_or_valid(model_args, curr_epoch, model, is_train=True):\\n    \\\"\\\"\\\"\\n    This fn. is used to train or validate the model\\n    params:\\n        model_args: a dict of model parameters\\n        curr_epoch: Current value of the epoch\\n        model: model to be trained\\n        is_train: can be True or False depending on whether to train or validate\\n\\n    returns:\\n        loss: sum of the loss across all tokens\\n\\n    \\\"\\\"\\\"\\n    loss_list = []\\n    y_pred_list = []\\n    y_list = []\\n    model_args[\\\"optimizer\\\"].zero_grad()\\n    if is_train:\\n        data_loader = get_data_loader(train_data, batch_size=model_args[\\\"batch_size\\\"])\\n        model.train()\\n    else:\\n        data_loader = get_data_loader(valid_data)\\n        model.eval()\\n\\n    with tqdm(data_loader, unit=\\\"batch\\\") as tepoch:\\n        tepoch.set_description(f\\\"Epoch {curr_epoch}\\\")\\n        for step, batch in enumerate(tepoch):\\n            X = batch[0]\\n            y = batch[1].float().to(DEVICE)\\n            y_pred, _ = model(X)\\n            y_pred_list.extend(y_pred.reshape(-1).tolist())\\n            y_list.extend(y.tolist())\\n            loss = model_args[\\\"criterion\\\"](y_pred.reshape(-1), y)\\n            loss_list.append(loss.item())\\n            if is_train:\\n                model_args[\\\"optimizer\\\"].zero_grad()\\n                loss.backward()\\n                nn.utils.clip_grad_norm_(model.parameters(), 2)\\n                model_args[\\\"optimizer\\\"].step()\\n                model_args[\\\"scheduler\\\"].step()\\n            tepoch.set_postfix(loss=sum(loss_list) / len(loss_list))\\n    if is_train is False:\\n        valid_data[f\\\"y_pred_{curr_epoch}\\\"] = y_pred_list\\n    else:\\n        train_data[f\\\"y_pred_{curr_epoch}\\\"] = y_pred_list\\n    return sum(loss_list) / len(loss_list), y_pred_list, y_list\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def train_or_valid(model_args, curr_epoch, model, is_train=True):\n",
    "    \"\"\"\n",
    "    This fn. is used to train or validate the model\n",
    "    params:\n",
    "        model_args: a dict of model parameters\n",
    "        curr_epoch: Current value of the epoch\n",
    "        model: model to be trained\n",
    "        is_train: can be True or False depending on whether to train or validate\n",
    "\n",
    "    returns:\n",
    "        loss: sum of the loss across all tokens\n",
    "\n",
    "    \"\"\"\n",
    "    loss_list = []\n",
    "    y_pred_list = []\n",
    "    y_list = []\n",
    "    model_args[\"optimizer\"].zero_grad()\n",
    "    train_type = None\n",
    "    if is_train:\n",
    "        data_loader = get_data_loader(train_data, batch_size=model_args[\"batch_size\"])\n",
    "        model.train()\n",
    "        train_type = \"train\"\n",
    "    else:\n",
    "        data_loader = get_data_loader(valid_data)\n",
    "        model.eval()\n",
    "        train_type = \"valid\"\n",
    "\n",
    "    with tqdm(data_loader, unit=\"batch\") as tepoch:\n",
    "        tepoch.set_description(f\"Epoch {curr_epoch} - {train_type}\")\n",
    "        for step, batch in enumerate(tepoch):\n",
    "            X = batch[0]\n",
    "            y = batch[1].float().to(DEVICE)\n",
    "            y_pred, _ = model(X)\n",
    "            y_pred_list.extend(y_pred.reshape(-1).tolist())\n",
    "            y_list.extend(y.tolist())\n",
    "            loss = model_args[\"criterion\"](y_pred.reshape(-1), y)\n",
    "            loss_list.append(loss.item())\n",
    "            if is_train:\n",
    "                model_args[\"optimizer\"].zero_grad()\n",
    "                loss.backward()\n",
    "                nn.utils.clip_grad_norm_(model.parameters(), 2)\n",
    "                model_args[\"optimizer\"].step()\n",
    "                model_args[\"scheduler\"].step()\n",
    "            tepoch.set_postfix(loss=sum(loss_list) / len(loss_list))\n",
    "    if is_train is False:\n",
    "        valid_data[f\"y_pred_{curr_epoch}\"] = y_pred_list\n",
    "    else:\n",
    "        train_data[f\"y_pred_{curr_epoch}\"] = y_pred_list\n",
    "    return sum(loss_list) / len(loss_list), y_pred_list, y_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fd559183",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 17;\n",
       "                var nbb_unformatted_code = \"# Defining parameters for the model\\ndef get_model_args():\\n    # returns a dict - {param: value}\\n    return {\\n        \\\"batch_size\\\": 128,\\n        \\\"epoch\\\": 10,\\n        \\\"learning_rate\\\": 0.0001,\\n    }\";\n",
       "                var nbb_formatted_code = \"# Defining parameters for the model\\ndef get_model_args():\\n    # returns a dict - {param: value}\\n    return {\\n        \\\"batch_size\\\": 128,\\n        \\\"epoch\\\": 10,\\n        \\\"learning_rate\\\": 0.0001,\\n    }\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Defining parameters for the model\n",
    "def get_model_args():\n",
    "    # returns a dict - {param: value}\n",
    "    return {\n",
    "        \"batch_size\": 128,\n",
    "        \"epoch\": 10,\n",
    "        \"learning_rate\": 0.0001,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d4713c6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 18;\n",
       "                var nbb_unformatted_code = \"import numpy as np\\nimport scipy\\n\\n\\\"\\\"\\\"\\n    https://numpy.org/doc/stable/reference/generated/numpy.corrcoef.html\\n    \\n\\\"\\\"\\\"\\n\\n\\ndef compute_r(y, y_pred):\\n    # corr = np.corrcoef(y, y_pred)\\n    corr = scipy.stats.pearsonr(y, y_pred)\\n    return corr\";\n",
       "                var nbb_formatted_code = \"import numpy as np\\nimport scipy\\n\\n\\\"\\\"\\\"\\n    https://numpy.org/doc/stable/reference/generated/numpy.corrcoef.html\\n    \\n\\\"\\\"\\\"\\n\\n\\ndef compute_r(y, y_pred):\\n    # corr = np.corrcoef(y, y_pred)\\n    corr = scipy.stats.pearsonr(y, y_pred)\\n    return corr\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "\n",
    "\"\"\"\n",
    "    https://numpy.org/doc/stable/reference/generated/numpy.corrcoef.html\n",
    "    \n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def compute_r(y, y_pred):\n",
    "    # corr = np.corrcoef(y, y_pred)\n",
    "    corr = scipy.stats.pearsonr(y, y_pred)\n",
    "    return corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e66d93e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 19;\n",
       "                var nbb_unformatted_code = \"def compute_language_correlation(valid_data, epoch):\\n    for language in valid_data[\\\"language\\\"].unique():\\n        r = compute_r(\\n            valid_data[valid_data[\\\"language\\\"] == language][f\\\"y_pred_{epoch}\\\"],\\n            valid_data[valid_data[\\\"language\\\"] == language][\\\"label\\\"],\\n        )\\n        print(f\\\"correlation for {language} is : {r}\\\")\";\n",
       "                var nbb_formatted_code = \"def compute_language_correlation(valid_data, epoch):\\n    for language in valid_data[\\\"language\\\"].unique():\\n        r = compute_r(\\n            valid_data[valid_data[\\\"language\\\"] == language][f\\\"y_pred_{epoch}\\\"],\\n            valid_data[valid_data[\\\"language\\\"] == language][\\\"label\\\"],\\n        )\\n        print(f\\\"correlation for {language} is : {r}\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def compute_language_correlation(valid_data, epoch):\n",
    "    for language in valid_data[\"language\"].unique():\n",
    "        r = compute_r(\n",
    "            valid_data[valid_data[\"language\"] == language][f\"y_pred_{epoch}\"],\n",
    "            valid_data[valid_data[\"language\"] == language][\"label\"],\n",
    "        )\n",
    "        print(f\"correlation for {language} is : {r}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c4a0b2e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at cardiffnlp/twitter-xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.decoder.bias', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.bias']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of XLMRobertaModel were not initialized from the model checkpoint at cardiffnlp/twitter-xlm-roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/soe/sgarg6/conda/envs/nlp_env/lib/python3.10/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Epoch 0: : 0batch [00:00, ?batch/s]Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "Epoch 0: : 119batch [00:02, 54.02batch/s, loss=4.64]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correlation for Italian is : PearsonRResult(statistic=-0.009417638233509919, pvalue=0.869888376448735)\n",
      "correlation for Spanish is : PearsonRResult(statistic=-0.007129546059024945, pvalue=0.8968714800545213)\n",
      "correlation for English is : PearsonRResult(statistic=-0.021372408312791868, pvalue=0.7055362480873175)\n",
      "correlation for Chinese is : PearsonRResult(statistic=0.007754695834997424, pvalue=0.8907887200541073)\n",
      "correlation for Portuguese is : PearsonRResult(statistic=0.09601351400115929, pvalue=0.0834676039359039)\n",
      "correlation for French is : PearsonRResult(statistic=-0.04594551255602811, pvalue=0.42474932164986434)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0: : 60batch [00:24,  2.41batch/s, loss=0.695]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[1.9224]], device='cuda:1', grad_fn=<AddmmBackward0>), {'input_ids': tensor([[    0,    55,  5189, 33050,  1606,    13,   501,    26,   525, 94889,\n",
      "             6,     3,     2]], device='cuda:1'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:1')})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0: : 119batch [00:02, 58.33batch/s, loss=0.438]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correlation for Italian is : PearsonRResult(statistic=-0.09140370708403195, pvalue=0.11114246887455122)\n",
      "correlation for Spanish is : PearsonRResult(statistic=0.021276430469528977, pvalue=0.6988729836137504)\n",
      "correlation for English is : PearsonRResult(statistic=0.0407204645996969, pvalue=0.47143749136395646)\n",
      "correlation for Chinese is : PearsonRResult(statistic=-0.007569058258786409, pvalue=0.8933873681674382)\n",
      "correlation for Portuguese is : PearsonRResult(statistic=-0.08425179586132776, pvalue=0.1289985553473082)\n",
      "correlation for French is : PearsonRResult(statistic=-0.011587739022142569, pvalue=0.8405315886049837)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: : 60batch [00:24,  2.41batch/s, loss=0.396]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[2.0455]], device='cuda:1', grad_fn=<AddmmBackward0>), {'input_ids': tensor([[    0,    55,  5189, 33050,  1606,    13,   501,    26,   525, 94889,\n",
      "             6,     3,     2]], device='cuda:1'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:1')})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: : 119batch [00:02, 58.31batch/s, loss=0.431]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correlation for Italian is : PearsonRResult(statistic=-0.07254212277345369, pvalue=0.20646099044008925)\n",
      "correlation for Spanish is : PearsonRResult(statistic=0.03654586848471423, pvalue=0.506297500197606)\n",
      "correlation for English is : PearsonRResult(statistic=0.05918301655785413, pvalue=0.2950365837325897)\n",
      "correlation for Chinese is : PearsonRResult(statistic=-0.010150523403957026, pvalue=0.8573651571951428)\n",
      "correlation for Portuguese is : PearsonRResult(statistic=-0.06889227059218354, pvalue=0.2147613807854946)\n",
      "correlation for French is : PearsonRResult(statistic=-0.0428673747794611, pvalue=0.4564642812380843)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: : 60batch [00:24,  2.43batch/s, loss=0.27] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[2.3844]], device='cuda:1', grad_fn=<AddmmBackward0>), {'input_ids': tensor([[    0,    55,  5189, 33050,  1606,    13,   501,    26,   525, 94889,\n",
      "             6,     3,     2]], device='cuda:1'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:1')})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: : 119batch [00:01, 61.32batch/s, loss=0.473]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correlation for Italian is : PearsonRResult(statistic=-0.09407826703126518, pvalue=0.10102618660465981)\n",
      "correlation for Spanish is : PearsonRResult(statistic=0.05763752760691705, pvalue=0.2943147270489873)\n",
      "correlation for English is : PearsonRResult(statistic=0.06297557163595707, pvalue=0.2651211282562871)\n",
      "correlation for Chinese is : PearsonRResult(statistic=0.009350812844734935, pvalue=0.8684964797736877)\n",
      "correlation for Portuguese is : PearsonRResult(statistic=-0.05633793459391853, pvalue=0.3105320360246191)\n",
      "correlation for French is : PearsonRResult(statistic=-0.037110418787639946, pvalue=0.5191872391971089)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: : 60batch [00:24,  2.44batch/s, loss=0.213]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[2.2585]], device='cuda:1', grad_fn=<AddmmBackward0>), {'input_ids': tensor([[    0,    55,  5189, 33050,  1606,    13,   501,    26,   525, 94889,\n",
      "             6,     3,     2]], device='cuda:1'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:1')})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: : 119batch [00:01, 63.14batch/s, loss=0.429]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correlation for Italian is : PearsonRResult(statistic=-0.07485571184778889, pvalue=0.19231516831298906)\n",
      "correlation for Spanish is : PearsonRResult(statistic=0.040150621986629116, pvalue=0.46525600234792425)\n",
      "correlation for English is : PearsonRResult(statistic=0.061525744013930225, pvalue=0.2763020195189506)\n",
      "correlation for Chinese is : PearsonRResult(statistic=-0.005340826940958793, pvalue=0.9246603121692467)\n",
      "correlation for Portuguese is : PearsonRResult(statistic=-0.06890571117620195, pvalue=0.21467172395702783)\n",
      "correlation for French is : PearsonRResult(statistic=-0.025754426631667268, pvalue=0.6546815162892282)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: : 60batch [00:24,  2.41batch/s, loss=0.148]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[2.2805]], device='cuda:1', grad_fn=<AddmmBackward0>), {'input_ids': tensor([[    0,    55,  5189, 33050,  1606,    13,   501,    26,   525, 94889,\n",
      "             6,     3,     2]], device='cuda:1'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:1')})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: : 119batch [00:01, 60.90batch/s, loss=0.44] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correlation for Italian is : PearsonRResult(statistic=-0.06023787439512113, pvalue=0.2943428591256399)\n",
      "correlation for Spanish is : PearsonRResult(statistic=0.054945984947660044, pvalue=0.31747739954843857)\n",
      "correlation for English is : PearsonRResult(statistic=0.06029688851351132, pvalue=0.2860259558097246)\n",
      "correlation for Chinese is : PearsonRResult(statistic=-0.01497149174027889, pvalue=0.7909330192966979)\n",
      "correlation for Portuguese is : PearsonRResult(statistic=-0.02669201574649458, pvalue=0.6311056135439079)\n",
      "correlation for French is : PearsonRResult(statistic=-0.03530758299198453, pvalue=0.5397018560175381)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: : 60batch [00:24,  2.42batch/s, loss=0.126]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[2.0877]], device='cuda:1', grad_fn=<AddmmBackward0>), {'input_ids': tensor([[    0,    55,  5189, 33050,  1606,    13,   501,    26,   525, 94889,\n",
      "             6,     3,     2]], device='cuda:1'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:1')})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: : 119batch [00:01, 59.63batch/s, loss=0.45] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correlation for Italian is : PearsonRResult(statistic=-0.073349927185449, pvalue=0.2014388692149436)\n",
      "correlation for Spanish is : PearsonRResult(statistic=0.04896759939464317, pvalue=0.3730637118824044)\n",
      "correlation for English is : PearsonRResult(statistic=0.0828349443944956, pvalue=0.14241640646168358)\n",
      "correlation for Chinese is : PearsonRResult(statistic=-0.015572305638173377, pvalue=0.7827484850976504)\n",
      "correlation for Portuguese is : PearsonRResult(statistic=-0.04432598784639197, pvalue=0.42507681464586144)\n",
      "correlation for French is : PearsonRResult(statistic=-0.03400942956229907, pvalue=0.5547196162113698)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: : 60batch [00:24,  2.41batch/s, loss=0.0943]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[2.0925]], device='cuda:1', grad_fn=<AddmmBackward0>), {'input_ids': tensor([[    0,    55,  5189, 33050,  1606,    13,   501,    26,   525, 94889,\n",
      "             6,     3,     2]], device='cuda:1'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:1')})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: : 119batch [00:02, 55.54batch/s, loss=0.422]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correlation for Italian is : PearsonRResult(statistic=-0.0568281865348885, pvalue=0.32257211998734664)\n",
      "correlation for Spanish is : PearsonRResult(statistic=0.058933254685519194, pvalue=0.2835766227987795)\n",
      "correlation for English is : PearsonRResult(statistic=0.0738491471240455, pvalue=0.19112193474244804)\n",
      "correlation for Chinese is : PearsonRResult(statistic=-0.005093284117791804, pvalue=0.9281426033774837)\n",
      "correlation for Portuguese is : PearsonRResult(statistic=-0.04965961171821406, pvalue=0.371463637988332)\n",
      "correlation for French is : PearsonRResult(statistic=-0.028600317521660583, pvalue=0.6193929454302324)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: : 60batch [00:24,  2.42batch/s, loss=0.0922]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[1.5180]], device='cuda:1', grad_fn=<AddmmBackward0>), {'input_ids': tensor([[    0,    55,  5189, 33050,  1606,    13,   501,    26,   525, 94889,\n",
      "             6,     3,     2]], device='cuda:1'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:1')})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: : 119batch [00:01, 60.72batch/s, loss=0.484]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correlation for Italian is : PearsonRResult(statistic=-0.06268180869597476, pvalue=0.2751544324926496)\n",
      "correlation for Spanish is : PearsonRResult(statistic=0.056950106888516684, pvalue=0.30012037601027747)\n",
      "correlation for English is : PearsonRResult(statistic=0.08188652731835583, pvalue=0.14705851243599402)\n",
      "correlation for Chinese is : PearsonRResult(statistic=-0.00481799264037527, pvalue=0.9320168530490346)\n",
      "correlation for Portuguese is : PearsonRResult(statistic=-0.0545248962349876, pvalue=0.3263849824778537)\n",
      "correlation for French is : PearsonRResult(statistic=-0.043027421102345254, pvalue=0.4547833047107144)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: : 60batch [00:24,  2.43batch/s, loss=0.0792]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[2.2565]], device='cuda:1', grad_fn=<AddmmBackward0>), {'input_ids': tensor([[    0,    55,  5189, 33050,  1606,    13,   501,    26,   525, 94889,\n",
      "             6,     3,     2]], device='cuda:1'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:1')})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: : 119batch [00:01, 60.54batch/s, loss=0.473]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correlation for Italian is : PearsonRResult(statistic=-0.07097159457276475, pvalue=0.21648261783215567)\n",
      "correlation for Spanish is : PearsonRResult(statistic=0.05229865069763004, pvalue=0.34138946958100147)\n",
      "correlation for English is : PearsonRResult(statistic=0.06981188187040256, pvalue=0.21659976337731027)\n",
      "correlation for Chinese is : PearsonRResult(statistic=-0.010435321222222502, pvalue=0.8534076908651228)\n",
      "correlation for Portuguese is : PearsonRResult(statistic=-0.05778970703214088, pvalue=0.298208895728377)\n",
      "correlation for French is : PearsonRResult(statistic=-0.04827563020460754, pvalue=0.40161749841184374)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: : 60batch [00:24,  2.41batch/s, loss=0.0623]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[2.0998]], device='cuda:1', grad_fn=<AddmmBackward0>), {'input_ids': tensor([[    0,    55,  5189, 33050,  1606,    13,   501,    26,   525, 94889,\n",
      "             6,     3,     2]], device='cuda:1'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:1')})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: : 119batch [00:01, 61.16batch/s, loss=0.442]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correlation for Italian is : PearsonRResult(statistic=-0.07048779576784311, pvalue=0.21963882458567177)\n",
      "correlation for Spanish is : PearsonRResult(statistic=0.055882989827333876, pvalue=0.3092823704655956)\n",
      "correlation for English is : PearsonRResult(statistic=0.0696466101353665, pvalue=0.2176922280327173)\n",
      "correlation for Chinese is : PearsonRResult(statistic=-0.003773051251101861, pvalue=0.9467364125064637)\n",
      "correlation for Portuguese is : PearsonRResult(statistic=-0.05836032214475204, pvalue=0.2934555669532354)\n",
      "correlation for French is : PearsonRResult(statistic=-0.04762620499712575, pvalue=0.4079877208933852)\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 20;\n",
       "                var nbb_unformatted_code = \"import time\\nfrom transformers import AdamW, get_linear_schedule_with_warmup\\n\\nmodel = MultiLingualModel(\\\"cardiffnlp/twitter-xlm-roberta-base\\\")\\nmodel_args = get_model_args()\\n# Loss and Optimization\\ntotal_steps = (len(train_data) / (model_args[\\\"batch_size\\\"])) * model_args[\\\"epoch\\\"]\\nmodel_args[\\\"criterion\\\"] = nn.MSELoss()\\nmodel_args[\\\"optimizer\\\"] = AdamW(\\n    model.parameters(), lr=model_args[\\\"learning_rate\\\"], eps=1e-8\\n)\\nmodel_args[\\\"scheduler\\\"] = get_linear_schedule_with_warmup(\\n    model_args[\\\"optimizer\\\"], num_warmup_steps=0, num_training_steps=total_steps\\n)\\n\\n# Log Metrics\\nepoch_train_loss = []\\nepoch_valid_loss = []\\nepoch_valid_r = []\\n# Begin Training\\n# validate the model\\nvalid_loss, valid_y_pred, valid_y = train_or_valid(model_args, 0, model, False)\\n# print(f\\\"Pearson's r is : {compute_r(valid_y_pred, valid_y)}\\\")\\ncompute_language_correlation(valid_data, 0)\\n\\nfor epoch in range(model_args[\\\"epoch\\\"]):\\n\\n    # Train the model\\n    train_loss, _, _ = train_or_valid(model_args, epoch, model)\\n    epoch_train_loss.append(train_loss)\\n    print(model(\\\"je suis japonaise c\\u2019est officiel \\ud83e\\udd74\\\"))\\n    # validate the model\\n    valid_loss, valid_y_pred, valid_y = train_or_valid(model_args, epoch, model, False)\\n    # print(f\\\"Pearson's r is : {compute_r(valid_y_pred, valid_y)}\\\")\\n    compute_language_correlation(valid_data, epoch)\\n    epoch_valid_loss.append(valid_loss)\\n    epoch_valid_r.append(compute_r)\";\n",
       "                var nbb_formatted_code = \"import time\\nfrom transformers import AdamW, get_linear_schedule_with_warmup\\n\\nmodel = MultiLingualModel(\\\"cardiffnlp/twitter-xlm-roberta-base\\\")\\nmodel_args = get_model_args()\\n# Loss and Optimization\\ntotal_steps = (len(train_data) / (model_args[\\\"batch_size\\\"])) * model_args[\\\"epoch\\\"]\\nmodel_args[\\\"criterion\\\"] = nn.MSELoss()\\nmodel_args[\\\"optimizer\\\"] = AdamW(\\n    model.parameters(), lr=model_args[\\\"learning_rate\\\"], eps=1e-8\\n)\\nmodel_args[\\\"scheduler\\\"] = get_linear_schedule_with_warmup(\\n    model_args[\\\"optimizer\\\"], num_warmup_steps=0, num_training_steps=total_steps\\n)\\n\\n# Log Metrics\\nepoch_train_loss = []\\nepoch_valid_loss = []\\nepoch_valid_r = []\\n# Begin Training\\n# validate the model\\nvalid_loss, valid_y_pred, valid_y = train_or_valid(model_args, 0, model, False)\\n# print(f\\\"Pearson's r is : {compute_r(valid_y_pred, valid_y)}\\\")\\ncompute_language_correlation(valid_data, 0)\\n\\nfor epoch in range(model_args[\\\"epoch\\\"]):\\n\\n    # Train the model\\n    train_loss, _, _ = train_or_valid(model_args, epoch, model)\\n    epoch_train_loss.append(train_loss)\\n    print(model(\\\"je suis japonaise c\\u2019est officiel \\ud83e\\udd74\\\"))\\n    # validate the model\\n    valid_loss, valid_y_pred, valid_y = train_or_valid(model_args, epoch, model, False)\\n    # print(f\\\"Pearson's r is : {compute_r(valid_y_pred, valid_y)}\\\")\\n    compute_language_correlation(valid_data, epoch)\\n    epoch_valid_loss.append(valid_loss)\\n    epoch_valid_r.append(compute_r)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import time\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "\n",
    "model = MultiLingualModel(\"cardiffnlp/twitter-xlm-roberta-base\")\n",
    "model_args = get_model_args()\n",
    "# Loss and Optimization\n",
    "total_steps = (len(train_data) / (model_args[\"batch_size\"])) * model_args[\"epoch\"]\n",
    "model_args[\"criterion\"] = nn.MSELoss()\n",
    "model_args[\"optimizer\"] = AdamW(\n",
    "    model.parameters(), lr=model_args[\"learning_rate\"], eps=1e-8\n",
    ")\n",
    "model_args[\"scheduler\"] = get_linear_schedule_with_warmup(\n",
    "    model_args[\"optimizer\"], num_warmup_steps=0, num_training_steps=total_steps\n",
    ")\n",
    "\n",
    "# Log Metrics\n",
    "epoch_train_loss = []\n",
    "epoch_valid_loss = []\n",
    "epoch_valid_r = []\n",
    "# Begin Training\n",
    "# validate the model\n",
    "valid_loss, valid_y_pred, valid_y = train_or_valid(model_args, 0, model, False)\n",
    "# print(f\"Pearson's r is : {compute_r(valid_y_pred, valid_y)}\")\n",
    "compute_language_correlation(valid_data, 0)\n",
    "\n",
    "for epoch in range(model_args[\"epoch\"]):\n",
    "\n",
    "    # Train the model\n",
    "    train_loss, _, _ = train_or_valid(model_args, epoch, model)\n",
    "    epoch_train_loss.append(train_loss)\n",
    "    print(model(\"je suis japonaise cest officiel \"))\n",
    "    # validate the model\n",
    "    valid_loss, valid_y_pred, valid_y = train_or_valid(model_args, epoch, model, False)\n",
    "    # print(f\"Pearson's r is : {compute_r(valid_y_pred, valid_y)}\")\n",
    "    compute_language_correlation(valid_data, epoch)\n",
    "    epoch_valid_loss.append(valid_loss)\n",
    "    epoch_valid_r.append(compute_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e7d9b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_valid_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "78b533cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[2.1301]], device='cuda:1', grad_fn=<AddmmBackward0>),\n",
       " {'input_ids': tensor([[    0,    55,  5189, 33050,  1606,    13,   501,    26,   525, 94889,\n",
       "              6,     3,     2]], device='cuda:1'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:1')})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 23;\n",
       "                var nbb_unformatted_code = \"model(\\\"je suis japonaise c\\u2019est officiel \\ud83e\\udd74\\\")\";\n",
       "                var nbb_formatted_code = \"model(\\\"je suis japonaise c\\u2019est officiel \\ud83e\\udd74\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model(\"je suis japonaise cest officiel \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ac3af789",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[2.1301]], device='cuda:1', grad_fn=<AddmmBackward0>),\n",
       " {'input_ids': tensor([[     0, 107662,   3060,  33881,  23282, 137384,     12,   1621,      2]],\n",
       "        device='cuda:1'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:1')})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 24;\n",
       "                var nbb_unformatted_code = \"model(\\\"Posting some VIP client tickets: http\\\")\";\n",
       "                var nbb_formatted_code = \"model(\\\"Posting some VIP client tickets: http\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model(\"Posting some VIP client tickets: http\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e795356d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>language</th>\n",
       "      <th>y_pred_0</th>\n",
       "      <th>y_pred_1</th>\n",
       "      <th>y_pred_2</th>\n",
       "      <th>y_pred_3</th>\n",
       "      <th>y_pred_4</th>\n",
       "      <th>y_pred_5</th>\n",
       "      <th>y_pred_6</th>\n",
       "      <th>y_pred_7</th>\n",
       "      <th>y_pred_8</th>\n",
       "      <th>y_pred_9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6800</th>\n",
       "      <td>Jour de Match on part  la guerre contre les q...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>French</td>\n",
       "      <td>1.832489</td>\n",
       "      <td>2.133482</td>\n",
       "      <td>1.957756</td>\n",
       "      <td>2.131768</td>\n",
       "      <td>2.091625</td>\n",
       "      <td>2.081552</td>\n",
       "      <td>2.044621</td>\n",
       "      <td>2.101458</td>\n",
       "      <td>2.123678</td>\n",
       "      <td>2.130066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6475</th>\n",
       "      <td>&amp;lt; pense  vmin tout le temps</td>\n",
       "      <td>1.80</td>\n",
       "      <td>French</td>\n",
       "      <td>1.832489</td>\n",
       "      <td>2.133482</td>\n",
       "      <td>1.957756</td>\n",
       "      <td>2.131768</td>\n",
       "      <td>2.091625</td>\n",
       "      <td>2.081552</td>\n",
       "      <td>2.044621</td>\n",
       "      <td>2.101458</td>\n",
       "      <td>2.123678</td>\n",
       "      <td>2.130066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2090</th>\n",
       "      <td>@user Y porque culpas a AMLO de que t mierda ...</td>\n",
       "      <td>2.25</td>\n",
       "      <td>Spanish</td>\n",
       "      <td>1.832489</td>\n",
       "      <td>2.133482</td>\n",
       "      <td>1.957756</td>\n",
       "      <td>2.131768</td>\n",
       "      <td>2.091625</td>\n",
       "      <td>2.081552</td>\n",
       "      <td>2.044621</td>\n",
       "      <td>2.101458</td>\n",
       "      <td>2.123678</td>\n",
       "      <td>2.130066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>532</th>\n",
       "      <td>I vindicate a obesity for tummy, kidnapper, an...</td>\n",
       "      <td>2.00</td>\n",
       "      <td>English</td>\n",
       "      <td>1.832489</td>\n",
       "      <td>2.133482</td>\n",
       "      <td>1.957756</td>\n",
       "      <td>2.131768</td>\n",
       "      <td>2.091625</td>\n",
       "      <td>2.081552</td>\n",
       "      <td>2.044621</td>\n",
       "      <td>2.101458</td>\n",
       "      <td>2.123678</td>\n",
       "      <td>2.130066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4965</th>\n",
       "      <td>ecco l'hanno fatto!   http</td>\n",
       "      <td>1.40</td>\n",
       "      <td>Italian</td>\n",
       "      <td>1.832489</td>\n",
       "      <td>2.133482</td>\n",
       "      <td>1.957756</td>\n",
       "      <td>2.131767</td>\n",
       "      <td>2.091625</td>\n",
       "      <td>2.081552</td>\n",
       "      <td>2.044621</td>\n",
       "      <td>2.101458</td>\n",
       "      <td>2.123678</td>\n",
       "      <td>2.130066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4034</th>\n",
       "      <td>noites mgicas, manhs trgicas </td>\n",
       "      <td>2.20</td>\n",
       "      <td>Portuguese</td>\n",
       "      <td>1.832489</td>\n",
       "      <td>2.133482</td>\n",
       "      <td>1.957756</td>\n",
       "      <td>2.131768</td>\n",
       "      <td>2.091625</td>\n",
       "      <td>2.081552</td>\n",
       "      <td>2.044621</td>\n",
       "      <td>2.101458</td>\n",
       "      <td>2.123678</td>\n",
       "      <td>2.130066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2402</th>\n",
       "      <td>Con sus ZAPATILLAS Trece Voto por Deja Vu en #...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>Spanish</td>\n",
       "      <td>1.832489</td>\n",
       "      <td>2.133482</td>\n",
       "      <td>1.957756</td>\n",
       "      <td>2.131768</td>\n",
       "      <td>2.091625</td>\n",
       "      <td>2.081552</td>\n",
       "      <td>2.044621</td>\n",
       "      <td>2.101458</td>\n",
       "      <td>2.123678</td>\n",
       "      <td>2.130066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7064</th>\n",
       "      <td>@user C'est le Coca-Cola</td>\n",
       "      <td>1.00</td>\n",
       "      <td>French</td>\n",
       "      <td>1.832489</td>\n",
       "      <td>2.133482</td>\n",
       "      <td>1.957756</td>\n",
       "      <td>2.131768</td>\n",
       "      <td>2.091625</td>\n",
       "      <td>2.081552</td>\n",
       "      <td>2.044621</td>\n",
       "      <td>2.101458</td>\n",
       "      <td>2.123678</td>\n",
       "      <td>2.130066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6320</th>\n",
       "      <td>Premire activit de 2021: nettoyer la pisse/d...</td>\n",
       "      <td>1.40</td>\n",
       "      <td>French</td>\n",
       "      <td>1.832489</td>\n",
       "      <td>2.133482</td>\n",
       "      <td>1.957756</td>\n",
       "      <td>2.131767</td>\n",
       "      <td>2.091625</td>\n",
       "      <td>2.081552</td>\n",
       "      <td>2.044621</td>\n",
       "      <td>2.101458</td>\n",
       "      <td>2.123678</td>\n",
       "      <td>2.130066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1453</th>\n",
       "      <td>#Felipe fmsmfmd</td>\n",
       "      <td>1.50</td>\n",
       "      <td>English</td>\n",
       "      <td>1.832489</td>\n",
       "      <td>2.133482</td>\n",
       "      <td>1.957756</td>\n",
       "      <td>2.131768</td>\n",
       "      <td>2.091625</td>\n",
       "      <td>2.081552</td>\n",
       "      <td>2.044621</td>\n",
       "      <td>2.101458</td>\n",
       "      <td>2.123678</td>\n",
       "      <td>2.130067</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  label    language  \\\n",
       "6800  Jour de Match on part  la guerre contre les q...   1.00      French   \n",
       "6475                  &lt; pense  vmin tout le temps   1.80      French   \n",
       "2090  @user Y porque culpas a AMLO de que t mierda ...   2.25     Spanish   \n",
       "532   I vindicate a obesity for tummy, kidnapper, an...   2.00     English   \n",
       "4965                   ecco l'hanno fatto!   http   1.40     Italian   \n",
       "4034                  noites mgicas, manhs trgicas    2.20  Portuguese   \n",
       "2402  Con sus ZAPATILLAS Trece Voto por Deja Vu en #...   1.00     Spanish   \n",
       "7064                           @user C'est le Coca-Cola   1.00      French   \n",
       "6320  Premire activit de 2021: nettoyer la pisse/d...   1.40      French   \n",
       "1453                                    #Felipe fmsmfmd   1.50     English   \n",
       "\n",
       "      y_pred_0  y_pred_1  y_pred_2  y_pred_3  y_pred_4  y_pred_5  y_pred_6  \\\n",
       "6800  1.832489  2.133482  1.957756  2.131768  2.091625  2.081552  2.044621   \n",
       "6475  1.832489  2.133482  1.957756  2.131768  2.091625  2.081552  2.044621   \n",
       "2090  1.832489  2.133482  1.957756  2.131768  2.091625  2.081552  2.044621   \n",
       "532   1.832489  2.133482  1.957756  2.131768  2.091625  2.081552  2.044621   \n",
       "4965  1.832489  2.133482  1.957756  2.131767  2.091625  2.081552  2.044621   \n",
       "4034  1.832489  2.133482  1.957756  2.131768  2.091625  2.081552  2.044621   \n",
       "2402  1.832489  2.133482  1.957756  2.131768  2.091625  2.081552  2.044621   \n",
       "7064  1.832489  2.133482  1.957756  2.131768  2.091625  2.081552  2.044621   \n",
       "6320  1.832489  2.133482  1.957756  2.131767  2.091625  2.081552  2.044621   \n",
       "1453  1.832489  2.133482  1.957756  2.131768  2.091625  2.081552  2.044621   \n",
       "\n",
       "      y_pred_7  y_pred_8  y_pred_9  \n",
       "6800  2.101458  2.123678  2.130066  \n",
       "6475  2.101458  2.123678  2.130066  \n",
       "2090  2.101458  2.123678  2.130066  \n",
       "532   2.101458  2.123678  2.130066  \n",
       "4965  2.101458  2.123678  2.130066  \n",
       "4034  2.101458  2.123678  2.130066  \n",
       "2402  2.101458  2.123678  2.130066  \n",
       "7064  2.101458  2.123678  2.130066  \n",
       "6320  2.101458  2.123678  2.130066  \n",
       "1453  2.101458  2.123678  2.130067  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 25;\n",
       "                var nbb_unformatted_code = \"valid_data.sample(10)\";\n",
       "                var nbb_formatted_code = \"valid_data.sample(10)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "valid_data.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69246402",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f8203e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"import time\n",
    "\n",
    "total_loss = []\n",
    "model.model.train()\n",
    "for epoch in range(5):\n",
    "    epoch_loss = []\n",
    "    train_data = data_loader(data)\n",
    "    for X, y in train_data:\n",
    "\n",
    "        y = y.float().to(DEVICE)\n",
    "        y_pred = model(X)\n",
    "        loss = mse_loss(y_pred[\"logits\"].reshape(-1), y)\n",
    "        optimizer.zero_grad()\n",
    "        epoch_loss.append(loss.item())\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.model.parameters(), 1)\n",
    "        optimizer.step()\n",
    "        del X, y, y_pred, loss\n",
    "        # del y, y_pred, loss\n",
    "        import gc\n",
    "\n",
    "        gc.collect()\n",
    "        with torch.cuda.device(DEVICE):\n",
    "            torch.cuda.empty_cache()\n",
    "    total_loss.append(sum(epoch_loss) / len(epoch_loss))\n",
    "    print(total_loss)\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
